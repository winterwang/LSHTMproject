\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Appendix0\_10},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{255,255,255}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.67,0.33,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.57,0.30,0.62}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.24,0.68,0.91}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{1.00,0.33,0.00}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{1.00,0.33,0.00}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.54,0.53,0.53}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.38,0.47,0.50}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.79,0.38,0.79}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.00,0.58,1.00}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.43,0.16}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.39,0.29,0.61}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.39,0.29,0.61}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.58,1.00}{\textbf{#1}}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.00,0.43,0.16}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.34,0.68}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.69,0.50,0.00}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{#1}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{\textbf{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.75,0.01,0.01}{\underline{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.12,0.11,0.11}{#1}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Appendix0\_10}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{}
    \preauthor{}\postauthor{}
    \date{}
    \predate{}\postdate{}
  

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# NDNS analysis, data management ------------------------------------------}

\CommentTok{# Change the data path accordingly ----------------------------------------}
\KeywordTok{setwd}\NormalTok{(}\StringTok{"/home/wangcc-me/Downloads/UKDA-6533-stata11_se/stata11_se/"}\NormalTok{) }\CommentTok{# on Ubuntu}
\KeywordTok{library}\NormalTok{(epiDisplay)}
\KeywordTok{library}\NormalTok{(plyr)}
\KeywordTok{library}\NormalTok{(tidyverse)}

\CommentTok{# Read the data into memory -----------------------------------------------}
\KeywordTok{library}\NormalTok{(haven)}
\NormalTok{data <-}\StringTok{ }\KeywordTok{read_dta}\NormalTok{(}\StringTok{"ndns_rp_yr1-4a_foodleveldietarydata_uk.dta"}\NormalTok{)}
\NormalTok{data56 <-}\StringTok{ }\KeywordTok{read_dta}\NormalTok{(}\StringTok{"ndns_rp_yr5-6a_foodleveldietarydata.dta"}\NormalTok{)}
\NormalTok{data78 <-}\StringTok{ }\KeywordTok{read_dta}\NormalTok{(}\StringTok{"ndns_rp_yr7-8a_foodleveldietarydata.dta"}\NormalTok{)}
\KeywordTok{names}\NormalTok{(data)}
\KeywordTok{names}\NormalTok{(data56)}
\KeywordTok{names}\NormalTok{(data78)}
\KeywordTok{names}\NormalTok{(data)[}\KeywordTok{names}\NormalTok{(data) }\OperatorTok{==}\StringTok{ "seriali"}\NormalTok{] <-}\StringTok{ "id"}
\KeywordTok{names}\NormalTok{(data56)[}\KeywordTok{names}\NormalTok{(data56) }\OperatorTok{==}\StringTok{ "seriali"}\NormalTok{] <-}\StringTok{ "id"}
\KeywordTok{names}\NormalTok{(data78)[}\KeywordTok{names}\NormalTok{(data78) }\OperatorTok{==}\StringTok{ "seriali"}\NormalTok{] <-}\StringTok{ "id"}

\CommentTok{# Extract the data we needed ----------------------------------------------}
\NormalTok{df14d <-}\StringTok{ }\NormalTok{data[, }\KeywordTok{c}\NormalTok{(}\DecValTok{113}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{55}\NormalTok{, }\DecValTok{57}\NormalTok{, }\DecValTok{58}\NormalTok{, }
    \DecValTok{59}\NormalTok{, }\DecValTok{60}\NormalTok{, }\DecValTok{61}\NormalTok{, }\DecValTok{62}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{64}\NormalTok{)]}
\NormalTok{var <-}\StringTok{ }\KeywordTok{names}\NormalTok{(df14d)}
\NormalTok{df56d <-}\StringTok{ }\NormalTok{data56 }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(var)}
\NormalTok{df78d <-}\StringTok{ }\NormalTok{data78 }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(var)}
\NormalTok{dfs1 <-}\StringTok{ }\KeywordTok{rbind}\NormalTok{(df14d, df56d, df78d)}
\NormalTok{dfs2 <-}\StringTok{ }\NormalTok{dfs1[dfs1}\OperatorTok{$}\NormalTok{Age }\OperatorTok{>=}\StringTok{ }\DecValTok{19}\NormalTok{, ]}
\KeywordTok{rm}\NormalTok{(data, data56, data78)}
\NormalTok{dfs2}

\CommentTok{# Calculate the time (minute and hour) when they eat ----------------------}

\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealTime_chr <-}\StringTok{ }\KeywordTok{as.character}\NormalTok{(dfs2}\OperatorTok{$}\NormalTok{MealTime)}
\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealTime_hm <-}\StringTok{ }\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(dfs2}\OperatorTok{$}\NormalTok{MealTime_chr, }\StringTok{" "}\NormalTok{))[}\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }
    \OtherTok{TRUE}\NormalTok{)]}
\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealHourN <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(dfs2}\OperatorTok{$}\NormalTok{MealTime_hm, }\StringTok{":"}\NormalTok{))[}\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }
    \OtherTok{FALSE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)])}
\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealMinN <-}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(}\KeywordTok{strsplit}\NormalTok{(dfs2}\OperatorTok{$}\NormalTok{MealTime_hm, }\StringTok{":"}\NormalTok{))[}\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }
    \OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)])}
\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealMinN0 <-}\StringTok{ }\NormalTok{(}\DecValTok{60} \OperatorTok{*}\StringTok{ }\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealHourN) }\OperatorTok{+}\StringTok{ }\NormalTok{dfs2}\OperatorTok{$}\NormalTok{MealMinN}
\NormalTok{dfs3 <-}\StringTok{ }\NormalTok{dfs2[}\KeywordTok{order}\NormalTok{(dfs2}\OperatorTok{$}\NormalTok{id, dfs2}\OperatorTok{$}\NormalTok{DayNo, dfs2}\OperatorTok{$}\NormalTok{MealMinN0), ]}
\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(dfs3}\OperatorTok{$}\NormalTok{id))  ## number of participants = 6155}

\CommentTok{# Create a subset data with only the first observation of each}
\CommentTok{# participant --------}
\NormalTok{NDNS <-}\StringTok{ }\NormalTok{dfs3[}\OperatorTok{!}\KeywordTok{duplicated}\NormalTok{(dfs3}\OperatorTok{$}\NormalTok{id), ]}
\KeywordTok{with}\NormalTok{(NDNS, }\KeywordTok{tab1}\NormalTok{(SurveyYear, }\DataTypeTok{graph =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{decimal =} \DecValTok{2}\NormalTok{))}

\CommentTok{# #SurveyYear :}
            \CommentTok{# Frequency Percent Cum. percent}
\CommentTok{# NDNS Year 1       801   13.01        13.01}
\CommentTok{# NDNS Year 2       812   13.19        26.21}
\CommentTok{# NDNS Year 3       782   12.71        38.91}
\CommentTok{# NDNS Year 4      1055   17.14        56.05}
\CommentTok{# NDNS Year 5       625   10.15        66.21}
\CommentTok{# NDNS Year 6       663   10.77        76.98}
\CommentTok{# NDNS Year 7       703   11.42        88.40}
\CommentTok{# NDNS Year 8       714   11.60       100.00}
  \CommentTok{# Total          6155  100.00       100.00}


\CommentTok{# create a variable combine id and day No ---------------------------------}
\NormalTok{dfs3 <-}\StringTok{ }\NormalTok{dfs3 }\OperatorTok{%>%}
\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{id_dy =} \KeywordTok{paste}\NormalTok{(id, DayNo, }\DataTypeTok{sep =} \StringTok{"D"}\NormalTok{))}

\CommentTok{# For each subject, the total energy/carbohydrate intake for each eating }
\CommentTok{# time can be calculated --------}
\NormalTok{old <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{Energy <-}\StringTok{ }\KeywordTok{ddply}\NormalTok{(dfs3, .(id_dy, id, SurveyYear, DayNo, Age, Sex, }
\NormalTok{                        DiaryDaysCompleted, MealHourN, DayofWeek), }
\NormalTok{                summarise, }
                \DataTypeTok{Tot_Energ =} \KeywordTok{sum}\NormalTok{(EnergykJ), }
                \DataTypeTok{Tot_Carb =} \KeywordTok{sum}\NormalTok{(Carbohydrateg), }
                \DataTypeTok{Tot_Sugar =} \KeywordTok{sum}\NormalTok{(Totalsugarsg), }
                \DataTypeTok{Tot_Starch =} \KeywordTok{sum}\NormalTok{(Starchg))}
\NormalTok{new <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{() }\OperatorTok{-}\StringTok{ }\NormalTok{old}
\KeywordTok{print}\NormalTok{(new)}
\CommentTok{# Time difference of 3.876385 mins}

\KeywordTok{rm}\NormalTok{(df14d, df56d, df78d, dfs2)}

\CommentTok{# Calculate the energy from total carbohydrates ---------------------------}
\NormalTok{Energy <-}\StringTok{ }\NormalTok{Energy }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{KJcarbo =}\NormalTok{ Tot_Carb }\OperatorTok{*}\StringTok{ }\DecValTok{16}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{CarKJpercentage =}\NormalTok{ KJcarbo}\OperatorTok{/}\NormalTok{Tot_Energ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Carbo =} \KeywordTok{cut}\NormalTok{(CarKJpercentage, }\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.26}\NormalTok{, }\FloatTok{0.75}\NormalTok{, }\DecValTok{2}\NormalTok{), }
        \DataTypeTok{right =} \OtherTok{FALSE}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Carbo2 =} \KeywordTok{cut}\NormalTok{(CarKJpercentage, }\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }
    \FloatTok{0.26}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{right =} \OtherTok{FALSE}\NormalTok{))}
\NormalTok{Energy0 <-}\StringTok{ }\NormalTok{Energy[}\OperatorTok{!}\NormalTok{(Energy}\OperatorTok{$}\NormalTok{Tot_Energ }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{), ]  }
          \CommentTok{# some food consumption does not contain any carbohydrates}
\NormalTok{Energy0}\OperatorTok{$}\NormalTok{Carbo <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(Energy0}\OperatorTok{$}\NormalTok{Carbo, }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Low_carb"}\NormalTok{, }\StringTok{"Med_carb"}\NormalTok{, }
    \StringTok{"High_carb"}\NormalTok{))}
\NormalTok{Energy0}\OperatorTok{$}\NormalTok{Carbo2 <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(Energy0}\OperatorTok{$}\NormalTok{Carbo2, }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Low_carb"}\NormalTok{, }\StringTok{"Med_or_high_carb"}\NormalTok{))}

\CommentTok{# Generate data sets for each day ----------------------------------------------------------}
\NormalTok{dta_day1 <-}\StringTok{ }\NormalTok{Energy0 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(DayNo }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"Age"}\NormalTok{, }
    \StringTok{"Sex"}\NormalTok{, }\StringTok{"DayofWeek"}\NormalTok{, }\StringTok{"MealHourN"}\NormalTok{, }\StringTok{"Carbo"}\NormalTok{, }\StringTok{"Carbo2"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{DayofWeek =} \KeywordTok{factor}\NormalTok{(DayofWeek, }
    \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Monday"}\NormalTok{, }\StringTok{"Tuesday"}\NormalTok{, }\StringTok{"Wednesday"}\NormalTok{, }\StringTok{"Thursday"}\NormalTok{, }\StringTok{"Friday"}\NormalTok{, }
        \StringTok{"Saturday"}\NormalTok{, }\StringTok{"Sunday"}\NormalTok{)))}

\NormalTok{dta_day2 <-}\StringTok{ }\NormalTok{Energy0 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(DayNo }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"Age"}\NormalTok{, }
    \StringTok{"Sex"}\NormalTok{, }\StringTok{"DayofWeek"}\NormalTok{, }\StringTok{"MealHourN"}\NormalTok{, }\StringTok{"Carbo"}\NormalTok{, }\StringTok{"Carbo2"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{DayofWeek =} \KeywordTok{factor}\NormalTok{(DayofWeek, }
    \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Monday"}\NormalTok{, }\StringTok{"Tuesday"}\NormalTok{, }\StringTok{"Wednesday"}\NormalTok{, }\StringTok{"Thursday"}\NormalTok{, }\StringTok{"Friday"}\NormalTok{, }
        \StringTok{"Saturday"}\NormalTok{, }\StringTok{"Sunday"}\NormalTok{)))}

\NormalTok{dta_day3 <-}\StringTok{ }\NormalTok{Energy0 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(DayNo }\OperatorTok{==}\StringTok{ }\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"Age"}\NormalTok{, }
    \StringTok{"Sex"}\NormalTok{, }\StringTok{"DayofWeek"}\NormalTok{, }\StringTok{"MealHourN"}\NormalTok{, }\StringTok{"Carbo"}\NormalTok{, }\StringTok{"Carbo2"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{DayofWeek =} \KeywordTok{factor}\NormalTok{(DayofWeek, }
    \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Monday"}\NormalTok{, }\StringTok{"Tuesday"}\NormalTok{, }\StringTok{"Wednesday"}\NormalTok{, }\StringTok{"Thursday"}\NormalTok{, }\StringTok{"Friday"}\NormalTok{, }
        \StringTok{"Saturday"}\NormalTok{, }\StringTok{"Sunday"}\NormalTok{)))}

\NormalTok{dta_day4 <-}\StringTok{ }\NormalTok{Energy0 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(DayNo }\OperatorTok{==}\StringTok{ }\DecValTok{4}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"id"}\NormalTok{, }\StringTok{"Age"}\NormalTok{, }
    \StringTok{"Sex"}\NormalTok{, }\StringTok{"DayofWeek"}\NormalTok{, }\StringTok{"MealHourN"}\NormalTok{, }\StringTok{"Carbo"}\NormalTok{, }\StringTok{"Carbo2"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{DayofWeek =} \KeywordTok{factor}\NormalTok{(DayofWeek, }
    \DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Monday"}\NormalTok{, }\StringTok{"Tuesday"}\NormalTok{, }\StringTok{"Wednesday"}\NormalTok{, }\StringTok{"Thursday"}\NormalTok{, }\StringTok{"Friday"}\NormalTok{, }
        \StringTok{"Saturday"}\NormalTok{, }\StringTok{"Sunday"}\NormalTok{)))}
\NormalTok{vecid1 <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(dta_day1}\OperatorTok{$}\NormalTok{id) }\CommentTok{# n = 6153}
\NormalTok{vecid2 <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(dta_day2}\OperatorTok{$}\NormalTok{id) }\CommentTok{# n = 6153}
\NormalTok{vecid3 <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(dta_day3}\OperatorTok{$}\NormalTok{id) }\CommentTok{# n = 6151}
\NormalTok{vecid4 <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(dta_day4}\OperatorTok{$}\NormalTok{id) }\CommentTok{# n = 6026}

\NormalTok{Noday1 <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(vecid, vecid1)  }\CommentTok{# two subjects did not have day 1 data}
\NormalTok{Noday2 <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(vecid, vecid2)  }\CommentTok{# two subjects did not have day 2 data}
\NormalTok{Noday3 <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(vecid, vecid3)  }\CommentTok{# four subjects did not have day 3 data}
\NormalTok{Noday4 <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(vecid, vecid4)  }\CommentTok{# 129 subjects did not have day 4 data}

\CommentTok{# Transform the data shape from long to wide ---------------------------------}
\NormalTok{dta_d1_wide <-}\StringTok{ }\NormalTok{dta_day1[, }\OperatorTok{-}\DecValTok{7}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ MealHourN, }\DataTypeTok{value =}\NormalTok{ Carbo)}
\KeywordTok{names}\NormalTok{(dta_d1_wide)[}\DecValTok{5}\OperatorTok{:}\DecValTok{28}\NormalTok{] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"H"}\NormalTok{, }\DecValTok{24}\NormalTok{), }\DecValTok{0}\OperatorTok{:}\DecValTok{23}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}

\NormalTok{dta_d2_wide <-}\StringTok{ }\NormalTok{dta_day2[, }\OperatorTok{-}\DecValTok{7}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ MealHourN, }\DataTypeTok{value =}\NormalTok{ Carbo)}
\KeywordTok{names}\NormalTok{(dta_d2_wide)[}\DecValTok{5}\OperatorTok{:}\DecValTok{28}\NormalTok{] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"H"}\NormalTok{, }\DecValTok{24}\NormalTok{), }\DecValTok{0}\OperatorTok{:}\DecValTok{23}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}

\NormalTok{dta_d3_wide <-}\StringTok{ }\NormalTok{dta_day3[, }\OperatorTok{-}\DecValTok{7}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ MealHourN, }\DataTypeTok{value =}\NormalTok{ Carbo)}
\KeywordTok{names}\NormalTok{(dta_d3_wide)[}\DecValTok{5}\OperatorTok{:}\DecValTok{28}\NormalTok{] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"H"}\NormalTok{, }\DecValTok{24}\NormalTok{), }\DecValTok{0}\OperatorTok{:}\DecValTok{23}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}

\NormalTok{dta_d4_wide <-}\StringTok{ }\NormalTok{dta_day4[, }\OperatorTok{-}\DecValTok{7}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ MealHourN, }\DataTypeTok{value =}\NormalTok{ Carbo)}
\KeywordTok{names}\NormalTok{(dta_d4_wide)[}\DecValTok{5}\OperatorTok{:}\DecValTok{28}\NormalTok{] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"H"}\NormalTok{, }\DecValTok{24}\NormalTok{), }\DecValTok{0}\OperatorTok{:}\DecValTok{23}\NormalTok{, }\DataTypeTok{sep =} \StringTok{""}\NormalTok{)}

\CommentTok{# recode NA to not eating -------------------------------------------------}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{5}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(dta_d1_wide)) }
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is.factor}\NormalTok{(dta_d1_wide[, i])) }\KeywordTok{levels}\NormalTok{(dta_d1_wide[, }
\NormalTok{    i]) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{levels}\NormalTok{(dta_d1_wide[, i]), }\StringTok{"Not_eating"}\NormalTok{)}

\NormalTok{dta_d1_wide[}\KeywordTok{is.na}\NormalTok{(dta_d1_wide)] <-}\StringTok{ "Not_eating"}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{5}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(dta_d2_wide)) }
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is.factor}\NormalTok{(dta_d2_wide[, i])) }\KeywordTok{levels}\NormalTok{(dta_d2_wide[, }
\NormalTok{    i]) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{levels}\NormalTok{(dta_d2_wide[, i]), }\StringTok{"Not_eating"}\NormalTok{)}

\NormalTok{dta_d2_wide[}\KeywordTok{is.na}\NormalTok{(dta_d2_wide)] <-}\StringTok{ "Not_eating"}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{5}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(dta_d3_wide)) }
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is.factor}\NormalTok{(dta_d3_wide[, i])) }\KeywordTok{levels}\NormalTok{(dta_d3_wide[, }
\NormalTok{    i]) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{levels}\NormalTok{(dta_d3_wide[, i]), }\StringTok{"Not_eating"}\NormalTok{)}

\NormalTok{dta_d3_wide[}\KeywordTok{is.na}\NormalTok{(dta_d3_wide)] <-}\StringTok{ "Not_eating"}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{5}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(dta_d4_wide)) }
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is.factor}\NormalTok{(dta_d4_wide[, i])) }\KeywordTok{levels}\NormalTok{(dta_d4_wide[, }
\NormalTok{    i]) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{levels}\NormalTok{(dta_d4_wide[, i]), }\StringTok{"Not_eating"}\NormalTok{)}

\NormalTok{dta_d4_wide[}\KeywordTok{is.na}\NormalTok{(dta_d4_wide)] <-}\StringTok{ "Not_eating"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Mplus VERSION 7.4
MUTHEN & MUTHEN
07/28/2018   9:55 AM

INPUT INSTRUCTIONS

  TITLE:    3-class at level 1 (CW), 3-classes at level 2 (CB) random effects model - non-pa
            ordered polytomous variables for carb intake at each time slot over four
            days of NDNS survey 2008/09 - 2015/16
            variable 0 = not eating
                     1 = eating & carb provided < 50% calorie
                     2 = eating & carb provided >= 50% calorie

  DATA:     File is H:\summer_project\Mplus\TimeSlots\NDNS_Tslots.dat;


  VARIABLE: NAMES = id id_dy Age Sex H6_9 H9_12 H12_14 H14_17 H17_20
                    H20_22 H22_6;

            USEVAR = H6_9 H9_12 H12_14 H14_17 H17_20
                    H20_22 H22_6;

            auxiliary = Age Sex;

            CATEGORICAL =  H6_9 H9_12 H12_14 H14_17 H17_20
                    H20_22 H22_6;

            CLUSTER = id;

            IDVARIABLE = id_dy;

            BETWEEN = CB;

            WITHIN = H6_9 H9_12 H12_14 H14_17 H17_20
                    H20_22 H22_6;

            CLASSES = CB(3) CW(3);

            MISSING are .;



  ANALYSIS:
  type = mixture twolevel;
  starts = 50 25;
  process = 8(starts);


  MODEL:
  %within%
  %overall%
  %between%
  %overall%
  CW ON CB;



  Savedata:
    file is H:\summer_project\Mplus\TimeSlots\Multilevel\NDNSslot_CW3CB3.txt;
    save is cprob;
    format is free;



3-class at level 1 (CW), 3-classes at level 2 (CB) random effects model - non-par
ordered polytomous variables for carb intake at each time slot over four
days of NDNS survey 2008/09 - 2015/16
variable 0 = not eating
1 = eating & carb provided < 50% calorie
2 = eating & carb provided >= 50% calorie

SUMMARY OF ANALYSIS

Number of groups                                                 1
Number of observations                                       24483

Number of dependent variables                                    7
Number of independent variables                                  0
Number of continuous latent variables                            0
Number of categorical latent variables                           2

Observed dependent variables

  Binary and ordered categorical (ordinal)
   H6_9        H9_12       H12_14      H14_17      H17_20      H20_22
   H22_6

Observed auxiliary variables
   AGE         SEX

Categorical latent variables
   CB          CW

Variables with special functions

  Cluster variable      ID
  ID variable           ID_DY

  Within variables
   H6_9        H9_12       H12_14      H14_17      H17_20      H20_22
   H22_6


Estimator                                                      MLR
Information matrix                                        OBSERVED
Optimization Specifications for the Quasi-Newton Algorithm for
Continuous Outcomes
  Maximum number of iterations                                 100
  Convergence criterion                                  0.100D-05
Optimization Specifications for the EM Algorithm
  Maximum number of iterations                                 500
  Convergence criteria
    Loglikelihood change                                 0.100D-02
    Relative loglikelihood change                        0.100D-05
    Derivative                                           0.100D-02
Optimization Specifications for the M step of the EM Algorithm for
Categorical Latent variables
  Number of M step iterations                                    1
  M step convergence criterion                           0.100D-02
  Basis for M step termination                           ITERATION
Optimization Specifications for the M step of the EM Algorithm for
Censored, Binary or Ordered Categorical (Ordinal), Unordered
Categorical (Nominal) and Count Outcomes
  Number of M step iterations                                    1
  M step convergence criterion                           0.100D-02
  Basis for M step termination                           ITERATION
  Maximum value for logit thresholds                            15
  Minimum value for logit thresholds                           -15
  Minimum expected cell size for chi-square              0.100D-01
Maximum number of iterations for H1                           2000
Convergence criterion for H1                             0.100D-03
Optimization algorithm                                         EMA
Integration Specifications
  Type                                                    STANDARD
  Number of integration points                                  15
  Dimensions of numerical integration                            0
  Adaptive quadrature                                           ON
Random Starts Specifications
  Number of initial stage random starts                         50
  Number of final stage optimizations                           25
  Number of initial stage iterations                            10
  Initial stage convergence criterion                    0.100D+01
  Random starts scale                                    0.500D+01
  Random seed for generating random starts                       0
Parameterization                                             LOGIT
Link                                                         LOGIT
Cholesky                                                       OFF

Input data file(s)
  H:\summer_project\Mplus\TimeSlots\NDNS_Tslots.dat
Input data format  FREE


SUMMARY OF DATA

     Number of missing data patterns             1
     Number of y missing data patterns           0
     Number of u missing data patterns           1
     Number of clusters                       6155



COVARIANCE COVERAGE OF DATA

Minimum covariance coverage value   0.100


UNIVARIATE PROPORTIONS AND COUNTS FOR CATEGORICAL VARIABLES

    H6_9
      Category 1    0.313         7655.000
      Category 2    0.184         4500.000
      Category 3    0.504        12328.000
    H9_12
      Category 1    0.222         5447.000
      Category 2    0.295         7227.000
      Category 3    0.482        11809.000
    H12_14
      Category 1    0.195         4783.000
      Category 2    0.454        11112.000
      Category 3    0.351         8588.000
    H14_17
      Category 1    0.283         6926.000
      Category 2    0.338         8277.000
      Category 3    0.379         9280.000
    H17_20
      Category 1    0.124         3043.000
      Category 2    0.582        14240.000
      Category 3    0.294         7200.000
    H20_22
      Category 1    0.356         8722.000
      Category 2    0.363         8898.000
      Category 3    0.280         6863.000
    H22_6
      Category 1    0.666        16295.000
      Category 2    0.169         4144.000
      Category 3    0.165         4044.000


RANDOM STARTS RESULTS RANKED FROM THE BEST TO THE WORST LOGLIKELIHOOD VALUES

Final stage loglikelihood values at local maxima, seeds, and initial stage start numbers:

         -166348.815  153942           31
         -166348.815  573096           20
         -166348.815  253358           2
         -166348.816  318230           46
         -166348.816  246261           38
         -166348.873  285380           1
         -166348.908  903420           5
         -166349.394  120506           45
         -166349.394  966014           37
         -166349.394  207896           25
         -166349.395  195873           6
         -166349.513  68985            17
         -166349.514  366706           29
         -166352.737  76974            16
         -166357.057  127215           9
         -166482.723  533738           11
         -166495.844  645664           39
         -166668.918  372176           23


THE BEST LOGLIKELIHOOD VALUE HAS BEEN REPLICATED.  RERUN WITH AT LEAST TWICE THE
RANDOM STARTS TO CHECK THAT THE BEST LOGLIKELIHOOD IS STILL OBTAINED AND REPLICATED.


THE MODEL ESTIMATION TERMINATED NORMALLY



MODEL FIT INFORMATION

Number of Free Parameters                      134

Loglikelihood

          H0 Value                     -166348.815
          H0 Scaling Correction Factor      1.8182
            for MLR

Information Criteria

          Akaike (AIC)                  332965.630
          Bayesian (BIC)                334051.799
          Sample-Size Adjusted BIC      333625.950
            (n* = (n + 2) / 24)



MODEL RESULTS USE THE LATENT CLASS VARIABLE ORDER

   CB  CW

  Latent Class Variable Patterns

         CB        CW
      Class     Class

         1         1
         1         2
         1         3
         2         1
         2         2
         2         3
         3         1
         3         2
         3         3


FINAL CLASS COUNTS AND PROPORTIONS FOR THE LATENT CLASS PATTERNS
BASED ON ESTIMATED POSTERIOR PROBABILITIES

  Latent Class
    Pattern

    1  1       4050.97975          0.16546
    1  2       1561.55249          0.06378
    1  3       1286.46696          0.05255
    2  1       2746.94031          0.11220
    2  2       3011.00217          0.12298
    2  3       1341.59686          0.05480
    3  1       2748.25320          0.11225
    3  2       4770.55950          0.19485
    3  3       2965.64876          0.12113


FINAL CLASS COUNTS AND PROPORTIONS FOR EACH LATENT CLASS VARIABLE
BASED ON ESTIMATED POSTERIOR PROBABILITIES

  Latent Class
    Variable    Class

    CB             1      6898.99902          0.28179
                   2      7099.53906          0.28998
                   3     10484.46094          0.42823
    CW             1      9546.17285          0.38991
                   2      9343.11426          0.38162
                   3      5593.71240          0.22847


FINAL CLASS COUNTS AND PROPORTIONS FOR THE LATENT CLASS PATTERNS
BASED ON THEIR MOST LIKELY LATENT CLASS PATTERN

Class Counts and Proportions

  Latent Class
    Pattern

    1  1             4262          0.17408
    1  2             1406          0.05743
    1  3             1178          0.04812
    2  1             2807          0.11465
    2  2             2946          0.12033
    2  3             1260          0.05146
    3  1             2745          0.11212
    3  2             5315          0.21709
    3  3             2564          0.10473


FINAL CLASS COUNTS AND PROPORTIONS FOR EACH LATENT CLASS VARIABLE
BASED ON THEIR MOST LIKELY LATENT CLASS PATTERN

  Latent Class
    Variable    Class

    CB             1            6846          0.27962
                   2            7013          0.28644
                   3           10624          0.43393
    CW             1            9814          0.40085
                   2            9667          0.39485
                   3            5002          0.20431


CLASSIFICATION QUALITY

     Entropy                         0.630


Average Latent Class Probabilities for Most Likely Latent Class Pattern (Row)
by Latent Class Pattern (Column)

  Latent Class Variable Patterns

  Latent Class         CB        CW
   Pattern No.      Class     Class

         1             1         1
         2             1         2
         3             1         3
         4             2         1
         5             2         2
         6             2         3
         7             3         1
         8             3         2
         9             3         3

           1        2        3        4        5        6        7        8        9

    1   0.720    0.091    0.073    0.016    0.032    0.004    0.005    0.033    0.025
    2   0.183    0.609    0.098    0.005    0.002    0.030    0.040    0.005    0.027
    3   0.211    0.084    0.629    0.008    0.005    0.007    0.011    0.036    0.009
    4   0.019    0.004    0.002    0.692    0.184    0.051    0.011    0.034    0.003
    5   0.042    0.001    0.001    0.158    0.709    0.045    0.001    0.035    0.009
    6   0.012    0.037    0.013    0.065    0.084    0.702    0.042    0.003    0.042
    7   0.011    0.029    0.004    0.012    0.002    0.022    0.641    0.126    0.153
    8   0.026    0.003    0.009    0.025    0.024    0.001    0.115    0.675    0.123
    9   0.046    0.024    0.004    0.003    0.010    0.018    0.079    0.174    0.642



MODEL RESULTS

                                                    Two-Tailed
                    Estimate       S.E.  Est./S.E.    P-Value

Within Level

Latent Class Pattern 1 1

 Thresholds
    H6_9$1            -0.718      0.218     -3.294      0.001
    H6_9$2             0.973      0.299      3.258      0.001
    H9_12$1           -2.516      0.463     -5.433      0.000
    H9_12$2            0.675      0.132      5.118      0.000
    H12_14$1          -1.025      0.145     -7.057      0.000
    H12_14$2           1.240      0.116     10.725      0.000
    H14_17$1          -1.566      0.149    -10.520      0.000
    H14_17$2           1.090      0.100     10.909      0.000
    H17_20$1          -1.998      0.125    -16.000      0.000
    H17_20$2           1.549      0.100     15.556      0.000
    H20_22$1          -0.933      0.085    -10.914      0.000
    H20_22$2           1.829      0.103     17.770      0.000
    H22_6$1            0.253      0.083      3.046      0.002
    H22_6$2            2.308      0.117     19.691      0.000

Latent Class Pattern 1 2

 Thresholds
    H6_9$1            -4.021      1.788     -2.249      0.025
    H6_9$2            -0.115      0.259     -0.445      0.656
    H9_12$1            0.167      0.373      0.448      0.654
    H9_12$2            2.142      0.586      3.657      0.000
    H12_14$1          -3.210      1.518     -2.115      0.034
    H12_14$2           0.858      0.167      5.124      0.000
    H14_17$1           0.044      0.384      0.114      0.909
    H14_17$2           1.617      0.293      5.509      0.000
    H17_20$1          -2.109      0.390     -5.409      0.000
    H17_20$2           1.399      0.196      7.126      0.000
    H20_22$1          -0.367      0.174     -2.109      0.035
    H20_22$2           2.347      0.382      6.151      0.000
    H22_6$1            0.754      0.259      2.912      0.004
    H22_6$2            2.542      0.264      9.646      0.000

Latent Class Pattern 1 3

 Thresholds
    H6_9$1           -15.000      0.000    999.000    999.000
    H6_9$2             2.357      0.783      3.011      0.003
    H9_12$1           -1.433      0.372     -3.850      0.000
    H9_12$2           -0.604      0.279     -2.166      0.030
    H12_14$1          -1.988      0.257     -7.749      0.000
    H12_14$2           0.524      0.125      4.209      0.000
    H14_17$1          -1.027      0.232     -4.436      0.000
    H14_17$2           0.274      0.131      2.087      0.037
    H17_20$1          -2.665      0.310     -8.605      0.000
    H17_20$2           0.707      0.112      6.322      0.000
    H20_22$1          -0.527      0.152     -3.462      0.001
    H20_22$2           0.702      0.138      5.102      0.000
    H22_6$1            1.119      0.185      6.062      0.000
    H22_6$2            1.748      0.183      9.544      0.000

Latent Class Pattern 2 1

 Thresholds
    H6_9$1             1.663      0.199      8.370      0.000
    H6_9$2             1.839      0.198      9.274      0.000
    H9_12$1           -2.150      0.281     -7.643      0.000
    H9_12$2           -0.869      0.140     -6.190      0.000
    H12_14$1          -1.978      0.191    -10.349      0.000
    H12_14$2           0.323      0.078      4.139      0.000
    H14_17$1           0.237      0.183      1.293      0.196
    H14_17$2           0.782      0.123      6.352      0.000
    H17_20$1          -2.936      0.428     -6.853      0.000
    H17_20$2           0.632      0.081      7.807      0.000
    H20_22$1           0.028      0.142      0.194      0.846
    H20_22$2           0.868      0.086     10.145      0.000
    H22_6$1            0.658      0.109      6.010      0.000
    H22_6$2            1.326      0.100     13.215      0.000

Latent Class Pattern 2 2

 Thresholds
    H6_9$1             1.640      0.171      9.619      0.000
    H6_9$2             1.906      0.179     10.678      0.000
    H9_12$1           -1.954      0.347     -5.636      0.000
    H9_12$2           -0.360      0.127     -2.842      0.004
    H12_14$1          -0.016      0.189     -0.084      0.933
    H12_14$2           0.948      0.135      7.029      0.000
    H14_17$1          -1.906      0.301     -6.327      0.000
    H14_17$2           0.371      0.080      4.614      0.000
    H17_20$1          -0.812      0.116     -7.030      0.000
    H17_20$2           0.910      0.089     10.259      0.000
    H20_22$1          -0.742      0.089     -8.318      0.000
    H20_22$2           0.998      0.085     11.705      0.000
    H22_6$1            0.298      0.083      3.608      0.000
    H22_6$2            1.337      0.099     13.475      0.000

Latent Class Pattern 2 3

 Thresholds
    H6_9$1            -1.072      0.500     -2.144      0.032
    H6_9$2            -0.309      0.346     -0.892      0.372
    H9_12$1            2.441      1.044      2.339      0.019
    H9_12$2            3.599      1.983      1.815      0.069
    H12_14$1          -1.029      0.211     -4.880      0.000
    H12_14$2           0.603      0.123      4.913      0.000
    H14_17$1          -0.010      0.243     -0.041      0.967
    H14_17$2           0.784      0.157      4.977      0.000
    H17_20$1          -0.953      0.203     -4.684      0.000
    H17_20$2           0.779      0.135      5.784      0.000
    H20_22$1          -0.105      0.210     -0.500      0.617
    H20_22$2           1.203      0.135      8.914      0.000
    H22_6$1            0.582      0.299      1.950      0.051
    H22_6$2            1.370      0.206      6.653      0.000

Latent Class Pattern 3 1

 Thresholds
    H6_9$1            -4.593      1.699     -2.703      0.007
    H6_9$2            -2.975      0.428     -6.957      0.000
    H9_12$1           -0.322      0.207     -1.553      0.120
    H9_12$2            0.398      0.363      1.095      0.274
    H12_14$1          -5.060      3.668     -1.380      0.168
    H12_14$2           0.307      0.100      3.080      0.002
    H14_17$1           0.186      0.530      0.351      0.726
    H14_17$2           0.317      0.245      1.295      0.195
    H17_20$1          -4.019      0.957     -4.199      0.000
    H17_20$2           0.747      0.093      7.987      0.000
    H20_22$1          -0.233      0.132     -1.767      0.077
    H20_22$2           0.607      0.109      5.571      0.000
    H22_6$1            1.304      0.146      8.918      0.000
    H22_6$2            1.850      0.160     11.579      0.000

Latent Class Pattern 3 2

 Thresholds
    H6_9$1            -1.232      0.195     -6.305      0.000
    H6_9$2            -0.858      0.169     -5.068      0.000
    H9_12$1           -4.377      1.937     -2.260      0.024
    H9_12$2           -1.488      0.316     -4.717      0.000
    H12_14$1          -1.727      0.227     -7.611      0.000
    H12_14$2           0.302      0.082      3.666      0.000
    H14_17$1          -1.834      0.237     -7.730      0.000
    H14_17$2          -0.294      0.186     -1.582      0.114
    H17_20$1          -2.588      0.487     -5.313      0.000
    H17_20$2           0.631      0.062     10.187      0.000
    H20_22$1          -0.920      0.078    -11.852      0.000
    H20_22$2           0.462      0.073      6.308      0.000
    H22_6$1            0.640      0.119      5.361      0.000
    H22_6$2            1.162      0.129      9.039      0.000

Latent Class Pattern 3 3

 Thresholds
    H6_9$1            -4.941      5.813     -0.850      0.395
    H6_9$2            -2.680      0.887     -3.024      0.002
    H9_12$1           -0.765      0.640     -1.195      0.232
    H9_12$2            1.164      0.920      1.265      0.206
    H12_14$1          -1.415      0.439     -3.226      0.001
    H12_14$2           0.566      0.085      6.626      0.000
    H14_17$1          -2.052      0.650     -3.158      0.002
    H14_17$2           0.612      0.210      2.909      0.004
    H17_20$1          -1.627      0.427     -3.810      0.000
    H17_20$2           0.713      0.103      6.935      0.000
    H20_22$1          -0.850      0.329     -2.585      0.010
    H20_22$2           0.685      0.134      5.104      0.000
    H22_6$1            1.237      0.195      6.349      0.000
    H22_6$2            1.893      0.179     10.582      0.000

Between Level

Categorical Latent Variables

Within Level

 Intercepts
    CW#1              -0.076      0.366     -0.208      0.835
    CW#2               0.475      0.309      1.539      0.124

Between Level

 CW#1       ON
    CB#1               1.223      0.473      2.585      0.010
    CB#2               0.793      0.441      1.796      0.073

 CW#2       ON
    CB#1              -0.282      0.535     -0.526      0.599
    CB#2               0.333      0.455      0.733      0.464

 Means
    CB#1              -0.417      0.100     -4.178      0.000
    CB#2              -0.386      0.067     -5.770      0.000


QUALITY OF NUMERICAL RESULTS

     Condition Number for the Information Matrix              0.428E-04
       (ratio of smallest to largest eigenvalue)


SAVEDATA INFORMATION


  Save file
    H:\summer_project\Mplus\TimeSlots\Multilevel\NDNSslot_CW3CB3.txt

  Order of variables

    H6_9
    H9_12
    H12_14
    H14_17
    H17_20
    H20_22
    H22_6
    ID_DY
    AGE
    SEX
    CPROB1
    CPROB2
    CPROB3
    CPROB4
    CPROB5
    CPROB6
    CPROB7
    CPROB8
    CPROB9
    CB
    CW
    MLCJOINT
    ID

  Save file format           Free

  Save file record length    10000


DIAGRAM INFORMATION

  Mplus diagrams are currently not available for Mixture analysis.
  No diagram output was produced.


     Beginning Time:  09:55:10
        Ending Time:  10:02:01
       Elapsed Time:  00:06:51



MUTHEN & MUTHEN
3463 Stoner Ave.
Los Angeles, CA  90066

Tel: (310) 391-9971
Fax: (310) 391-8971
Web: www.StatModel.com
Support: Support@StatModel.com

Copyright (c) 1998-2015 Muthen & Muthen
\end{verbatim}


\end{document}
